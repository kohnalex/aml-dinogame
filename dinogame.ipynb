{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35599db9",
   "metadata": {},
   "source": [
    "### 1. Setup Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ad67bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip --version && python --version\n",
    "%conda install -y pytorch torchvision torchaudio -c pytorch\n",
    "%pip install stable-baselines3[extra] protobuf\n",
    "%pip install pytesseract mss pydirectinput opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d92502e",
   "metadata": {},
   "source": [
    "### 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ff685",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mss import mss\n",
    "import pydirectinput\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from gym import Env\n",
    "from gym.spaces import Box, Discrete\n",
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common import env_checker\n",
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ecf6a7",
   "metadata": {},
   "source": [
    "### 3. Define Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79de0ce",
   "metadata": {},
   "source": [
    "#### 3.1 Game Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf325b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebGame(Env):\n",
    "    # Setup the environment action and observation shapes\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Setup spaces\n",
    "        self.observation_space = Box(low=0, high=255, shape=(1, 20, 25), dtype=np.uint8)\n",
    "        self.action_space = Discrete(2) # We have three actions in total\n",
    "\n",
    "        # Define extraction parameters for the game\n",
    "        self.cap = mss()\n",
    "\n",
    "        # Spaces on screen for game action and game over\n",
    "        self.game_location = {\n",
    "            'top': 310,\n",
    "            'left': 170,\n",
    "            'width': 180,\n",
    "            'height': 45\n",
    "        }\n",
    "        self.done_location = {\n",
    "            'top': 240,\n",
    "            'left': 260,\n",
    "            'width': 250,\n",
    "            'height': 35\n",
    "        }\n",
    "\n",
    "    # Called to do sth in the game\n",
    "    def step(self, action):\n",
    "        # Action key - 0 = Jump (Space), 1 = Duck (down), 2 = Nothin()\n",
    "        action_map = {\n",
    "            0: 'space',\n",
    "            1: 'nothing',\n",
    "        }\n",
    "        \n",
    "        if action != 1:\n",
    "            pydirectinput.press(action_map[action])\n",
    "\n",
    "        done, done_cap = self.get_done()\n",
    "        new_observation = self.get_observation()\n",
    "\n",
    "        # Reward for every frame we are alive\n",
    "        reward = 1\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        return new_observation, reward, done, info\n",
    "\n",
    "    \n",
    "    def render(self):\n",
    "        winname = \"Game\"\n",
    "        cv2.namedWindow(winname)\n",
    "        cv2.moveWindow(winname, 1500, 800)\n",
    "        cv2.imshow(winname, np.array(self.cap.grab(self.game_location))[:,:,:3])\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            self.close()\n",
    "\n",
    "\n",
    "    # Reset the game\n",
    "    def reset(self):\n",
    "        time.sleep(1)\n",
    "        pydirectinput.click(x=150, y=150)\n",
    "        pydirectinput.press('space')\n",
    "        return self.get_observation()\n",
    "\n",
    "    # Close observation\n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    # Get the part og the observation of the game that we want\n",
    "    def get_observation(self):\n",
    "        # TODO: Adjust screen cap and resize params\n",
    "        # Get screen capture of game\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3]\n",
    "        # Grayscale\n",
    "        gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n",
    "        # Resize\n",
    "        resized = cv2.resize(gray, (25, 20))\n",
    "        # Add channles\n",
    "        channel = np.reshape(resized, (1,20,25))\n",
    "        return channel\n",
    "\n",
    "    # Get the game over text\n",
    "    def get_done(self):\n",
    "        # Get game over screen using pytesseract\n",
    "        cap = np.array(self.cap.grab(self.done_location))[:,:,:3]\n",
    "        # Valid done text. We just take the first word, and give some room for failure to speed things up\n",
    "        done_strings = ['GAME', 'GAHE', 'GANE']\n",
    "\n",
    "        done = False\n",
    "        # Apply OCR\n",
    "        res = pytesseract.image_to_string(cap)[:4]\n",
    "        if res in done_strings:\n",
    "            done = True\n",
    "\n",
    "        return done, cap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df36847e",
   "metadata": {},
   "source": [
    "#### 3.2 Logging Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3695f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "            \n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8265922",
   "metadata": {},
   "source": [
    "### Show observation and done screen cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a98927c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = WebGame()\n",
    "plt.imshow(env.get_observation()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b979ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WebGame()\n",
    "done, cap = env.get_done()\n",
    "print(done)\n",
    "plt.imshow(cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51066164",
   "metadata": {},
   "source": [
    "### Environment Test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e733c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env = WebGame()\n",
    "\n",
    "# Make sure environment is setup properly\n",
    "env_checker.check_env(env)\n",
    "\n",
    "# Make a few testruns\n",
    "for episode in range(4):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        obs, reward, done, info = env.step(env.action_space.sample())\n",
    "        total_reward += reward\n",
    "    print(f\"Total reward for episode {episode} is {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train_final/'\n",
    "LOG_DIR = './logs_final/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10fdc92",
   "metadata": {},
   "source": [
    "#### Train existing model (load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c05c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WebGame()\n",
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)              \n",
    "model = DQN.load(\"./out/best_model_30000.zip\",env=env)\n",
    "model.learn(reset_num_timesteps=False, total_timesteps=100_000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fbf682",
   "metadata": {},
   "source": [
    "#### Train new model (creatae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5328a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = WebGame()\n",
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)              \n",
    "model = DQN('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, buffer_size=70_000, learning_starts=1000)\n",
    "model.learn(total_timesteps=120_000, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6acf50",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a482e611",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WebGame()\n",
    "model = DQN.load(\"./train_final/best_model_47000.zip\",env=env, print_system_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed22d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 10\n",
    "for ep in range(episodes):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(int(action))\n",
    "        env.render()\n",
    "\n",
    "env.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b27d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('aml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a1f337cc9d6c804d896dbe62d455a8c3614f816a4571ce89fff87abf286d4b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
